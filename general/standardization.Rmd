---
title: Should we standardize the log-counts?
author: Aaron Lun
date: "`r Sys.Date()`"
output:
  BiocStyle::html_document:
    toc: true
    toc_float: true
bibliography: ref.bib
---   

```{r, echo=FALSE, message=FALSE}
library(BiocStyle)
knitr::opts_chunk$set(error=FALSE, message=FALSE, warning=FALSE)
```

# Rationale

Standardization involves scaling all features so that they have the same (unit) variance across all samples.
This is commonly recommended for features that are not directly comparable (e.g., annual income, lifespan, education level) prior to computing an objective function.
It ensures that the objective function is not solely determined by the feature with the largest variance, as this has no meaning when the variances are not comparable.
In scRNA-seq contexts, standardization ensures that all genes contribute the same amount of variance to downstream steps like PCA and clustering.
However, this has a number of drawbacks that are not often considered by analysts.

# Inappropriate gene weighting

Standardizing will downweight the contribution of interesting genes with large total variances due to biological heterogeneity. 
This will reduce the resolution of biological differences between cell populations.
Of course, some genes may just be biologically noisy, but more often than not, large biological components will represent some interesting structured variation.
Conversely, standardization will upweight genes with low total variance and small (non-zero) biological components.
This will amplify biological variability that was originally minor, which may be misleading.

```{r}
set.seed(10)
a <- matrix(rnorm(100000), ncol=100)
a[1:10,1:50] <- a[1:10,1:50] + 10

out.raw <- prcomp(t(a))
out.sca <- prcomp(t(a), scale=TRUE)

# Populations are less clearly separated after scaling.
col <- rep(c("blue", "red"), each=50)
plot(out.raw$x[,1], out.raw$x[,2], col=col, main="Raw")
plot(out.sca$x[,1], out.sca$x[,2], col=col, main="Scaled")
```

Distances between subpopulations also become unnecessarily inter-dependent in standardized data.
To illustrate, imagine a dataset containing two subpopulations.
One of them highly expresses gene $X$, while the other only has moderate expression - thus, we are able to distinguish these two populations on the expression of gene $X$.
Now, imagine adding a third subpopulation that is silent for gene $X$.
If standardization is performed, this will reduce the power of $X$ to discriminate between the first two subpopulations.
This is counterintuitive as nothing has changed between the first two subpopulations.

# Distortion of log-fold changes

Any scaling distorts the true log-fold changes for genes between subpopulations.
This affects interpretation of relative distances between three or more groups of cells.
In particular, it becomes difficult to determine whether two groups are more related to each other than to a third group.

One could argue that log-fold changes of different genes are not comparable anyway.
A 2-fold change in a cell type-defining marker gene may be more important than a 10-fold change in another gene involved in cell cycle or something.
Even so, it is hard to see how standardization does any better in this regard than using the unbiased estimates of the log-fold changes, 
as neither incorporate _a priori_ knowledge about the importance of the genes.

Under certain conditions, standardization means that the magnitude of the separation between populations is driven by the number of DEGs, not their log-fold changes.
Again, this is not clearly better (or worse) than computing distances based on the magnitude of the log-fold changes.

# Alternative scaling approaches

The use for standardization would require us to assume that biological differences in variance between genes are not interesting.
A slightly more appropriate approach is to remove differences in the technical component of variation.
This aim would be to avoid domination of the results by genes with large technical components due to the nature of the mean-variance trend.
The problem with this strategy is that genes with very low technical components (e.g., high-abundance genes) would be strongly scaled up.
This would inflate their biological components, allowing them to dominate and effectively inverting the original problem.

Another option is to scale each gene such that its variance becomes equal to the biological component.
This accounts for the mean-variance trend and upweights genes with large biological components rather than penalizing them.
Conversely, genes with near-zero biological components are effectively ignored during the PCA.
However, this is still an _ad hoc_ strategy.
For total variance $V$ decomposed into $B + T$, the rescaled biological component becomes $B^2/V$ while the rescaled technical component is $TB/V$;
neither of these values has much meaning to me, and treating them as $B$ and $T$ would clearly be wrong unless $T = 0$.

# Concluding remarks

Standardization effectively weights each gene in inverse proportion to its variance.
In this respect, standardization can be viewed as another feature selection step.
However, I would argue that the effects of standardization are largely undesirable in scRNA-seq contexts where we expect to see large differences in variance between genes due to biology.
It is true that large differences in the technical components are also present, but it is not clear how to remove them without distorting the biological differences.

I believe that _not_ performing standardization is the best approach in routine applications.
This allows genes with large biological components to drive systematic separation in downstream analyses.
While genes with large technical components will also drive separation, this should be stochastic and removable by denoising.

# Session information

```{r}
sessionInfo()
```
