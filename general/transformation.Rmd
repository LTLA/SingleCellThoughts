---
title: What transformation should we use?
author: Aaron Lun
date: "`r Sys.Date()`"
output:
  BiocStyle::html_document:
    toc: true
    toc_float: true
bibliography: ref.bib
---   

```{r, echo=FALSE, message=FALSE}
library(BiocStyle)
knitr::opts_chunk$set(error=FALSE, message=FALSE, warning=FALSE)
set.seed(120000)
```

# Rationale

Transformation of expression data aims to achieve variance stabilization, i.e., an identical noise distribution for all observations.
This simplifies downstream analyses by circumventing the need for complex models to account for the mean-variance relationship.
For example, one could apply linear models directly under the assumption of i.i.d. normal errors. 

In the context of scRNA-seq data analysis, the motivation for transformation is more nebulous.
Most common procedures are not model-based and do not assume i.i.d. errors in the first place.
Nonetheless, there are some benefits to using transformed data, which allows us:

- To avoid high-abundance genes from driving population heterogeneity, simply because they have higher variance.
  Transformation aims to equalize the contribution of all genes to high-dimensional procedures like clustering.
- To ensure that the population variance is independent of the coverage of that population.
  For example, a population with deeper sequencing/coverage would have larger counts and greater variance without transformation,
  which may be misleading for comparisons of heterogeneity (e.g., to study differentiation priming).
- To improve the dynamic range of expression values and thus resolution of differences.
  For example, in a mixture of three populations with mean counts of 1, 10 and 100, 
  the first two are effectively indistinguishable without transformation.
- To simplify interpretation of downstream statistics.
  In particular, distances in log-transformed data can be treated as an estimate of the log-fold change in the (normalized) counts.

# Philosophical issues

Let's assume that it is possible to equalize the contribution of each gene to population heterogeneity.
There is no reason that this would offer any benefit to the downstream analysis. 
For example, if relevant expression differences occurred in high-abundance genes, 
it would be better to avoid transformation prior to procedures such as clustering.
Of course, this is unlikely to be the case but it is equally unlikely to assume that relevant genes will be evenly distributed across the abundance range.

Attempting to equalize the contribution of each gene may also be misguided in a biological context.
For example, in log-transformed data, highly expressed genes will often have very low variances.
This mean-variance relationship can be considered to be biologically relevant as such genes need to be stably expressed.
Removing it with variance stabilization may do more harm than good in downstream analyses.

The optimal transformation would be the one that gave greatest weight to the abundance interval containing the most relevant genes.
Of course, the relevance of a gene is either unknown or in the eye of the beholder;
however, generally speaking, this refers to genes that have only moderate-to-low average expression across the data set.
This is because they are likely to be upregulated in some cells and downregulated in others,
and thus be associated with biological heterogeneity within the population.

# Practical challenges

## With low counts

No transformation can achieve complete variance stabilization in scRNA-seq data [@lun2018overcoming], especially UMI data.
At a mean of zero, the variance is necessarily zero.
At any non-zero mean, the variance can only increase from zero.
Thus, there is an inherent mean-variance relationship that cannot be removed by any (monotonic) transformation.
This is particularly relevant for UMI data due to the low counts and high frequency of zeroes.

## Handling biological variation

Transformation to stabilize noise will not necessarily remove the mean dependence on the biological variation.
Consider some counts with Poisson-distributed noise. 
For the Poisson distribution, the variance stabilizing transformation (VST) is the square root function.
While this stabilizes the Poisson component at high means, any overdispersion will manifest as an increasing mean-variance trend:

```{r, fig.wide=TRUE}
library(matrixStats)
mu <- 2^seq(0, 10, length.out=100)
y <- matrix(rpois(length(mu)*1000, lambda=mu), nrow=length(mu))
v <- rowVars(sqrt(y))

y2 <- matrix(rnbinom(length(mu)*1000, mu=mu, size=10), nrow=length(mu))
v2 <- rowVars(sqrt(y2))

par(mfrow=c(1,2))
plot(mu, v, xlab="Mean", ylab="Variance", main="Poisson", log="x")
plot(mu, v2, xlab="Mean", ylab="Variance", main="Overdispersed", log="x")
```

This is unlikely to be desirable, as it means that high-abundance genes can dominate the downstream analyses.
Similarly, a two-fold change in expression has a different effect depending on the abundance:

```{r}
y3 <- cbind(
    matrix(rpois(length(mu)*500, lambda=mu), nrow=length(mu)),
    matrix(rpois(length(mu)*500, lambda=mu*2), nrow=length(mu))
)
v3 <- rowVars(sqrt(y3))
plot(mu, v3, xlab="Mean", ylab="Variance", main="Overdispersed", log="x")
vl <- rowVars(log(y3+1)) # log-transformation, for comparison.
plot(mu, vl, xlab="Mean", ylab="Variance", main="Overdispersed", log="x")
```

This is most obviously problematic for high-dimensional procedures that involve implicit comparisons between genes, e.g., clustering.
However, it will also compromise any comparisons across different means, e.g., log-fold change estimates, testing for interaction effects.

One might suggest that the choice of VST should instead be based on the mean-variance relationship after including the biological component.
This simply shifts the problem; any overdispersion above the trend would have different effects at different means.
We will explore this more in the next section.

# Empirically determining the best VST

It was proposed to me that we should use the `vst` function from `r Biocpkg("DESeq2")` to perform the transformation.
However, this does not avoid any of the issues described above with inappropriate scaling of the biological component.
Consider the following example, where two genes separate two groups of cells:

```{r}
set.seed(1000)
ngenes <- 1000
means <- 2^sort(runif(ngenes, 5, 10))
dispersion <- 10/means + 0.1

ncells <- 200
counts <- matrix(rnbinom(ngenes*ncells, mu=means, size=1/dispersion), 
    ncol=ncells)

# Adding DE at low and high abundances.
half <- seq_len(100)
counts[1,half] <- rnbinom(ncells/2, mu=means[1]*2, size=1/dispersion[1])
counts[ngenes,half] <- rnbinom(ncells/2, mu=means[ngenes]*2, 
    size=1/dispersion[ngenes])
```

Using `vst` and a simple log-transformation in this simulation indicates that only the latter preserves the size of the log-fold change across abundances.

```{r}
library(DESeq2)
outV <- vst(counts)
mean(outV[1,half]) - mean(outV[1,-half]) # not 1.
mean(outV[ngenes,half]) - mean(outV[ngenes,-half]) # close to 1.

outL <- log2(counts + 1)    
mean(outL[1,half]) - mean(outL[1,-half]) # close to 1.
mean(outL[ngenes,half]) - mean(outL[ngenes,-half]) # close to 1.
```

The counts are pretty large here, so the value of the pseudo-count should not be an issue, nor should there be any shrinkage to compensate for Poisson noise.
Rather, this is due to the fact that `vst` automatically squeezes values together more strongly when the count data are noisy, in order to stabilize the variance.
Less squeezing occurs at higher counts, resulting in a distortion of the log-fold changes (equivalent to that of the biological component).

# Concluding remarks

In a scRNA-seq context, transformation can be viewed as a feature weighting problem that depends on abundance.
The choice of transformation will either upweight high-abundance genes or low-abundance genes,
either due to imperfect stabilization of noise or due to the inability to stabilize overdispersion above the mean-variance trend.
Once we accept this, it becomes clear that there is no optimal transformation without knowing the most important features _a priori_.

To this end, the log-transformation is probably satisfactory.
It is fast, simple to compute and ensures that log-fold changes are preserved as constant differences in the transformed space (at high abundances, at least).
The main complaint is that the pseudo-count must be manually specified.
However, we can view this as a tuning parameter that determines the abundance-dependent weighting,
with smaller pseudo-counts increasing the weight of genes with lower abundances. 

# Session information

```{r}
sessionInfo()
```

# References


